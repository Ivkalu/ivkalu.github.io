<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Luka IvankoviÄ‡ | ML Engineer</title>
    <!--<link rel="icon" href="VD.png" type="image/png">-->
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="assets/css/portfolio.css">
    <link rel="stylesheet" href="assets/css/custom.css">
</head>
<body>

    <header>
        <h1>Luka IvankoviÄ‡</h1>
        <p class="subtitle">Machine Learning Engineer <span class="separator">|</span> Dev Ops <span class="separator">|</span> Full-Stack Developer</p>
        <div class="contact">
            <a href="mailto:ivkalu@gmail.com"><i class="fas fa-envelope"></i> ivkalu@gmail.com</a>
            <a href="https://github.com/ivkalu"><i class="fab fa-github"></i> GitHub</a>
            <a href="music.html"><i class="fas fa-music"></i> Music</a>
            <!--<a href="CV">ðŸ“œ CV</a>-->
        </div>
    </header>

<section>
    <p><strong>About me:</strong></p>
    <p>
        Iâ€™m a creative, enthusiastic, and competitive developer with a strong foundation in software engineering and a passion for machine learning and music tech. 
        I'm currently wrapping up my masterâ€™s thesis at the Faculty of Electrical Engineering and Computing,
        where Iâ€™ve delved into advanced audio signal processing and deep learning. My research focuses on emulating guitar effects using neural networks.
        Iâ€™m deeply motivated by the challenge of learning new things, which fuels my technical versatility, leadership, and drive to turn bold ideas into reliable, scalable solutions. 
        As Cal Newport puts it, <em>"The ability to learn quickly is a superpower in today's fast-paced world."</em>
    </p>


    <p><strong>About me again:</strong></p>
    <p>
        Besides programming I enjoy listening, playing and composing music. I am a self-taught guitarist and recently I bought a piano which became my new favorite obsession.
        I believe both programming and playing instruments tackle the same creative part of the brain. I regularly train to keep my body and mind healthy. Naturally these full-body workouts make me hungry, so I also enjoy cooking.
        I'm a casual D&D player and enjoy kicking ass in Catan.
    </p>
</section>


<section>
    <h2>Projects</h2>

    <a href="https://dnd-session-creator-frontend-275331783644.europe-west1.run.app/" class="project-link">
        <div class="project">
            <p><strong>D&D Session Creator (Agentic Campaign Assistant)</strong></p>
            <p>
                Built a full-stack platform for Dungeon Masters to manage campaigns, organize documents, and chat with an
                AI agent that knows their entire campaign world. Players upload PDFs, Word docs, and text files - the system
                extracts the content and makes it searchable by a sandboxed AI assistant equipped with tools inspired by
                <strong>Claude Code</strong> (Grep, Read, Glob, and more).
            </p>
            <p>
                The agent is built on <strong>Agency Swarm</strong> and the <strong>OpenAI Agents SDK</strong>,
                running inside an isolated per-request workspace. The backend uses <strong>FastAPI</strong> with <strong>MongoDB</strong>
                and <strong>AWS S3</strong>, while the frontend is a <strong>Nuxt 3</strong> app with <strong>Firebase</strong> authentication.
            </p>
            <div class="image-wrapper">
                <img src="assets/img/dnd-architecture.png"
                     alt="D&D Session Creator Architecture"
                     class="project-image"
                     width="500">
            </div>
        </div>
    </a>

    <a href="https://synesearch-556510469420.europe-west1.run.app/" class="project-link">
        <div class="project">
            <p><strong>SyneSearch (Agentic RAG Financial Chatbot)</strong></p>
            <p>
                Fine-tuned embedding models and built three variations of a <strong>Retrieval-Augmented Generation (RAG)</strong>
                system - from naive chunking to fully agentic retrieval - then ran comparative analyses to find the best approach.
                The agentic pipeline, where the LLM decides when and how to search, delivered the strongest results and was
                integrated as a chatbot into an existing financial application.
            </p>
            <p>
                The system uses <strong>LangChain</strong> for orchestration, a <strong>vector database</strong> for semantic search
                over financial documents, and custom fine-tuned embeddings to improve domain-specific retrieval accuracy.
            </p>
            <div class="image-wrapper">
                <img src="assets/img/synesearch-architecture.png"
                     alt="SyneSearch Architecture"
                     class="project-image">
            </div>
        </div>
    </a>

    <a href="https://github.com/Ivkalu/agentic-pdf-reconstructor" class="project-link">
    <div class="project">
        <p><strong>Agentic PDF Reconstructor (Multi-Agent LaTeX Synthesis)</strong></p>
        <p>
            Built an autonomous <strong>multi-agent system</strong> that reconstructs documents from images into 
            <strong>pixel-accurate LaTeX PDFs</strong>. A Reconstructor agent infers layout, typography, tables, and formulas,
            while an Analyzer agent compares the generated PDF to the source image and provides structured feedback for iterative refinement.
        </p>
        <p>
            Developed with <strong>LangGraph</strong> and <strong>LangChain</strong>, the system runs as a self-directed
            think â†’ act â†’ observe loop with tool-based reasoning and automatic error recovery. Includes a semantic
            <strong>Video Analyzer</strong> using OCR, TF-IDF, and clustering to extract representative frames.
        </p>
        <div class="image-wrapper">
            <img src="assets/img/pdf-analyzer.png"
                 alt="Agentic PDF Reconstructor Architecture"
                 class="project-image">
        </div>
    </div>
</a>

    <a href="https://github.com/Ivkalu/genetic-image-creator" class="project-link">
        <div class="project">
            <p><strong>Genetic Algorithm for Image Recreation</strong></p>
            <p>
                Developed a genetic algorithm in Python using <strong>Pygame</strong> to recreate target images. Successfully approximated the Mona Lisa by evolving polygon-based visuals, optimized using a human-perception-based color metric.
            </p>
            <div class="image-wrapper">
                <img src="assets/img/genetic.png" alt="Genetic Algorithm for Image Recreation" class="project-image">
            </div>
        </div>
    </a>

    <a href="https://github.com/Ivkalu/NEAT" class="project-link">
        <div class="project">
            <p><strong>Neuroevolution of Augmenting Topologies</strong></p>
            <p>
                Implemented the NEAT algorithm to evolve neural networks capable of playing the <strong>Chrome Dinosaur Game</strong>. 
                The system trained agents to learn jumping and ducking behavior purely through evolutionary strategies, without any hardcoded rules. 
                After several generations, the best-performing network was able to achieve a score of over 10,000, effectively beating the game.
            </p>
            <div class="image-wrapper">
                <img src="assets/img/NEAT.png" alt="NEAT" class="project-image">
            </div>
        </div>
    </a>

    <a href="https://github.com/Ivkalu/mandelbrot-set" class="project-link">
        <div class="project">
            <p><strong>Mandelbrot & Julia Set Visualiser</strong></p>
            <p>
                Created a real-time Mandelbrot and Julia set visualizer using <strong>C++</strong> and the <strong>SDL2</strong> library. 
                The Julia set dynamically updates based on the mouse position, allowing users to interactively explore both fractals and zoom in almost indefinitely, revealing their intricate self-similarity and complexity.
            </p>
            <div class="image-wrapper">
                <img src="assets/img/mandelbrot.png" alt="Mandelbrot set" class="project-image" width="400">
            </div>
        </div>
    </a>
        
</section>

<section>
    <h2>Competitions</h2>
    
    <p style="margin-bottom: 40px;">
        I'm a very competitive person and enjoy testing my skills in real-world challenges. 
        Over the years, I've participated in a variety of hackathons and algorithm competitions, including the 
        <strong>Algotrade Hackathon</strong> 2024, <strong>AI-Battlegrounds Hackathon</strong> 2024 (which I won), and the 
        <strong>National Competition in Algorithms</strong> (2017 & 2018), where I gained valuable experience in creative problem-solving under pressure.
    </p>

    <a href="https://github.com/rangoiv/Lumen" class="project-link">
        <div class="project">
            <p><strong>Lumen Datascience 2023 - Audio Instrument Classification</strong></p>
            <p>
                This project was a team effort between me and my brother for the Lumen Datascience competition. 
                We tackled the problem of audio instrument classification using deep learning. 
                Models like <strong>VGG16</strong>, <strong>SqueezeNet</strong>, and <strong>ResNet18</strong> were trained 
                to classify which instruments appeared in a given audio clip, reaching up to <strong>90.4% accuracy</strong>.
            </p>
            <div class="image-wrapper">
                <img src="assets/img/lumen.png" alt="Lumen Datascience" class="project-image" width="400">
            </div>
        </div>
    </a>

    <a href="https://rangoiv.itch.io/dream-depths" class="project-link">
        <div class="project">
            <p><strong>Ludum Dare 2025 - Dream Depths</strong></p>
            <p>
                This game was created during a 3-day game jam by a team of 4 developers. The theme challenged us to design a game centered around exploring other peopleâ€™s dreams a concept inspired by Inception. Dive deeper into the dreams of NPCs, uncover hidden layers of their subconscious, and perhaps even discover The Chosen One. Fight off enemy agents trying to stop you along the way.
                This was our first time using the <strong>Godot game engine</strong> - a fun and rewarding learning experience
            </p>
            <div class="image-wrapper">
                <img src="assets/img/ludum-dare.png" alt="Ludum Dare Game" class="project-image" width="400">
            </div>
        </div>
    </a>

    

</section>

<section>
    <h2>Theses</h2>

    <a href="docs/Zavrsni_rad.pdf" download target="_blank" class="thesis-link">
        <div class="thesis">
            <p><strong>Bachelorâ€™s thesis - Deep learning for symbol recognition inside computer game</strong></p>
            <p>
            I developed a multiplayer combat game with a unique shape-drawing mechanic. The client was written in <strong>C++</strong> using the <strong>SDL2</strong> library for rendering, while the server was implemented in <strong>Python</strong>. Communication between the client and server was handled using <strong>TCP sockets</strong>.
            <br><br>
            A <strong>ResNet18</strong> model was <strong>fine-tuned</strong> to recognize objects that players drew on screen. Based on the classification results (achieving 99% accuracy) players could perform different types of attacks.
            </p>

            <div class="image-wrapper">
                <img src="assets/img/resnet18.png" alt="Bachelor's Thesis Photo" class="project-image">
            </div>
        </div>
    </a>

    <a href="docs/Master.pdf" download target="_blank" class="thesis-link">
        <div class="thesis">
            <p><strong>Masterâ€™s thesis - Emulation of Guitar Effects Using Machine Learning</strong></p>
            <p>
                This thesis explores the use of machine learning to emulate guitar effect pedals such as distortion and reverb. Traditional analog and DSP-based designs can be complex and time-consuming to model, especially due to the nonlinear and time-dependent nature of audio processing. The project investigates both black-box and gray-box approaches: starting with fully connected networks and advancing to architectures like <strong>LSTMs</strong>, <strong>WaveNet</strong>, <strong>TCNs</strong>, and <strong>Transformers</strong>. Gray-box methods such as genetic algorithms and differentiable DSP are also explored and compared.
            </p>
            <div class="image-wrapper">
                <img src="assets/img/masters-thesis.png" alt="Master's Thesis Photo" class="project-image" width="400">
            </div>
        </div>
    </a>
    

</section>

</body>
</html>
